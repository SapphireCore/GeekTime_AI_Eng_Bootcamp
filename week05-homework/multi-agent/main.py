# è¿è¡Œæ–¹å¼ï¼š
# 1) å¯åŠ¨ MCP æœåŠ¡å™¨ï¼ˆç»ˆç«¯ Aï¼‰ï¼š
#    python main.py server --host 127.0.0.1 --port 8000
#
# 2) å¯åŠ¨ LangGraph å¤šä»£ç†å†™ä½œå®¢æˆ·ç«¯ï¼ˆç»ˆç«¯ Bï¼‰ï¼š
#    python main.py client --topic "å†™ä¸€ç¯‡ä»‹ç»RAGç†è®ºä¸ç ”ç©¶å‰æ²¿çš„æ–‡ç« " --style "é€šä¿—ä½†ä¸“ä¸š" --length 1400
#
# 3) è¾“å‡ºä¼šåœ¨å½“å‰ç›®å½•ç”Ÿæˆï¼š
#    article_output_YYYYMMDD_HHMMSS.md
#
# ä¾èµ–ï¼š
#   pip install fastmcp duckduckgo-search langgraph langchain langchain-community langchain-mcp-adapters python-dotenv
#
#
# è¯´æ˜ï¼š
# - æœ¬æ–‡ä»¶åŒæ—¶åŒ…å«ï¼šMCP å·¥å…·æœåŠ¡å™¨ + LangGraph å¤šä»£ç†å·¥ä½œæµ + ä¸‰çº§é‡è¯•ç­–ç•¥
# - æœç´¢å·¥å…·ä½¿ç”¨ DuckDuckGoï¼ˆduckduckgo-searchï¼‰ï¼›ç½‘ç»œä¸å¯ç”¨æ—¶ä¼šè§¦å‘é‡è¯•å¹¶é™çº§

from __future__ import annotations

import argparse
import asyncio
import datetime as _dt
import json
import os
import sys
import textwrap
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, TypedDict, Tuple

# -----------------------------
# Optional dependencies import
# -----------------------------
_FASTMCP_OK = True
_DDGS_OK = True
_LANGGRAPH_OK = True
_MCP_ADAPTER_OK = True
_TONGYI_OK = True

try:
    from fastmcp import FastMCP
except Exception:
    _FASTMCP_OK = False

try:
    from duckduckgo_search import DDGS
except Exception:
    _DDGS_OK = False

try:
    from langgraph.graph import StateGraph, END
except Exception:
    _LANGGRAPH_OK = False

try:
    from langchain_mcp_adapters.client import MultiServerMCPClient
    from langchain_mcp_adapters.tools import load_mcp_tools
except Exception:
    _MCP_ADAPTER_OK = False

try:
    # é€šä¹‰åƒé—®ï¼ˆç¤ºä¾‹ä¸åŠ©æ•™æ ·ä¾‹ä¸€è‡´ï¼‰ï¼›è‹¥ä¸å¯ç”¨åˆ™èµ° Mock
    from langchain_community.chat_models import ChatTongyi
    from langchain_core.messages import SystemMessage, HumanMessage
except Exception:
    _TONGYI_OK = False

try:
    from dotenv import load_dotenv
except Exception:
    # ä¸å¼ºä¾èµ– dotenv
    load_dotenv = None


# -----------------------------
# Prompts
# -----------------------------
RESEARCH_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªAIç ”ç©¶å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç»™å®šçš„ä¸»é¢˜ï¼Œä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†ç›¸å…³ä¿¡æ¯ï¼Œå¹¶è¾“å‡ºä¸€ä»½ç»“æ„åŒ–çš„ç ”ç©¶èµ„æ–™ï¼ˆMarkdownï¼‰ã€‚

è¾“å‡ºå¿…é¡»åŒ…å«ï¼š
1) æ ¸å¿ƒæ¦‚å¿µï¼šå…³é”®æœ¯è¯­ä¸å®šä¹‰ï¼ˆç”¨ç®€æ´ä½†å‡†ç¡®çš„è¡¨è¿°ï¼‰
2) å…³é”®æŠ€æœ¯/æœºåˆ¶ï¼šåˆ—å‡º 5-8 ä¸ªå…³é”®ç‚¹ï¼Œæ¯ä¸ªç‚¹ 2-4 å¥è¯´æ˜
3) ä»£è¡¨æ€§è®ºæ–‡/ç³»ç»Ÿï¼šæŒ‰å¹´ä»½åˆ—å‡º 6-10 æ¡ï¼ˆæ ‡é¢˜ã€ä½œè€…/æœºæ„ã€è´¡çŒ®ç‚¹ï¼‰
4) å·¥ç¨‹å®è·µè¦ç‚¹ï¼šæ•°æ®ã€æ£€ç´¢ã€é‡æ’ã€ç”Ÿæˆã€è¯„ä¼°ã€ç›‘æ§ç­‰è‡³å°‘ 6 æ¡å»ºè®®
5) é£é™©ä¸è¯¯åŒºï¼šè‡³å°‘ 5 æ¡ï¼ˆå¦‚å¹»è§‰ã€è¿‡æ‹Ÿåˆæ£€ç´¢ã€è¯„ä¼°åå·®ã€éšç§åˆè§„ç­‰ï¼‰
6) å‚è€ƒé“¾æ¥ï¼šç»™å‡ºæ¥æº URL åˆ—è¡¨ï¼ˆå¯ä»æœç´¢ç»“æœä¸­æå–ï¼‰

çº¦æŸï¼š
- ç ”ç©¶èµ„æ–™è¦â€œå¯å¤ç”¨ã€å¯å¼•ç”¨ã€å¯ä¸‹æ¸¸å†™ä½œâ€ï¼Œé¿å…ç©ºæ³›å£å·
- å¯¹äºä¸ç¡®å®šçš„ç»“è®ºè¦æ˜¾å¼æ ‡æ³¨â€œå¯èƒ½/é€šå¸¸/åœ¨éƒ¨åˆ†å·¥ä½œä¸­â€
"""

WRITING_PROMPT = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIç§‘æŠ€æ–‡ç« æ’°ç¨¿äººã€‚æ ¹æ®ç ”ç©¶èµ„æ–™æ’°å†™æ–‡ç« åˆç¨¿ï¼ˆMarkdownï¼‰ã€‚

è¦æ±‚ï¼š
- æ–‡ç« ç»“æ„ï¼šå¼•è¨€ â†’ åŸç†ä¸èŒƒå¼ â†’ å…³é”®æŠ€æœ¯æ ˆ â†’ è¯„ä¼°ä¸è½åœ° â†’ å‰æ²¿æ–¹å‘ â†’ ç»“è¯­
- è¯­è¨€ï¼šé¢å‘å·¥ç¨‹è¯»è€…ï¼Œâ€œé€šä¿—ä½†ä¸“ä¸šâ€ï¼Œé¿å…å­¦æœ¯è…”å †ç Œ
- é£æ ¼ï¼š{style}
- é•¿åº¦ï¼šçº¦ {length} å­—
- å¿…é¡»åŒ…å«ï¼šè‡³å°‘ä¸€ä¸ªå¯¹æ¯”è¡¨ï¼ˆä¾‹å¦‚ï¼šRAG vs Fine-tuning vs Tool-useï¼‰ï¼Œè‡³å°‘ä¸€æ®µâ€œè½åœ° checklistâ€
"""

REVIEW_PROMPT = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æŠ€æœ¯ç¼–è¾‘ä¸å®¡ç¨¿äººã€‚è¯·å®¡æŸ¥æ–‡ç« åˆç¨¿ï¼ˆMarkdownï¼‰ï¼Œè¾“å‡ºâ€œé—®é¢˜æ¸…å• + ä¿®æ”¹å»ºè®®â€ã€‚

è‡³å°‘è¦†ç›–ï¼š
- äº‹å®å‡†ç¡®æ€§ä¸è¡¨è¿°é£é™©ï¼ˆæ˜¯å¦å­˜åœ¨è¿‡åº¦æ–­è¨€ï¼‰
- ç»“æ„ä¸é€»è¾‘ï¼ˆæ˜¯å¦æœ‰è·³è·ƒã€å†—ä½™ã€ç¼ºå…³é”®æ®µï¼‰
- å·¥ç¨‹å¯è½åœ°æ€§ï¼ˆè¯„ä¼°æŒ‡æ ‡ã€ç›‘æ§ã€æ•°æ®æ²»ç†æ˜¯å¦å…·ä½“ï¼‰
- è¯­è¨€ä¸ä¸€è‡´æ€§ï¼ˆæœ¯è¯­ç»Ÿä¸€ã€æ®µè½è¡”æ¥ï¼‰
- å¼•ç”¨ä¸æ¥æºï¼ˆæ˜¯å¦ç¼ºå…³é”®å‚è€ƒï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»ï¼‰ï¼š
1) æ€»ä½“è¯„ä»·ï¼ˆ2-4 å¥ï¼‰
2) é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼ˆP0ï¼‰åˆ—è¡¨ï¼ˆä¸å°‘äº 5 æ¡ï¼‰
3) ä¸­ä¼˜å…ˆçº§é—®é¢˜ï¼ˆP1ï¼‰åˆ—è¡¨ï¼ˆä¸å°‘äº 5 æ¡ï¼‰
4) ä½ä¼˜å…ˆçº§å»ºè®®ï¼ˆP2ï¼‰åˆ—è¡¨ï¼ˆä¸å°‘äº 3 æ¡ï¼‰
"""

POLISHING_PROMPT = """
ä½ æ˜¯ä¸€ä½é¡¶çº§æŠ€æœ¯å†™ä½œæ¶¦è‰²ä¸“å®¶ã€‚è¯·ç»“åˆâ€œæ–‡ç« åˆç¨¿ + å®¡æ ¸å»ºè®®â€ï¼Œç”Ÿæˆæœ€ç»ˆç»ˆç¨¿ï¼ˆMarkdownï¼‰ã€‚

è¦æ±‚ï¼š
- é‡‡çº³æ‰€æœ‰åˆç†çš„ P0/P1 å»ºè®®
- ä¿æŒç»“æ„æ¸…æ™°ã€è¯­è¨€ä¸€è‡´
- å¯¹ä¸ç¡®å®šç»“è®ºåŠ é™å®šè¯­æˆ–è¡¥å¼•ç”¨
- ä¿ç•™å¹¶ä¼˜åŒ–ï¼šå¯¹æ¯”è¡¨ã€checklistã€å‰æ²¿æ–¹å‘
- ä¸è¦è¾“å‡ºé¢å¤–è§£é‡Šï¼Œåªè¾“å‡ºæœ€ç»ˆæ–‡ç« æ­£æ–‡
"""

# å¤‡ç”¨å®¡æ ¸/æ¶¦è‰²ä»£ç†ï¼ˆç”¨äºäºŒçº§é‡è¯•ï¼‰
SENIOR_REVIEW_PROMPT = """
ä½ æ˜¯â€œé«˜çº§æŠ€æœ¯å®¡ç¨¿äººâ€ï¼Œæ ‡å‡†æ¯”æ™®é€šå®¡æ ¸æ›´ä¸¥æ ¼ã€‚è¯·å¯¹æ–‡ç« åˆç¨¿è¿›è¡Œæ›´ç»†è‡´çš„å®¡é˜…ä¸é£é™©æ§åˆ¶ï¼Œå°¤å…¶å…³æ³¨ï¼š
- æ˜¯å¦å­˜åœ¨äº‹å®æ€§é”™è¯¯æˆ–è¿‡åº¦è¥é”€å¼è¡¨è¿°
- æ¦‚å¿µè¾¹ç•Œæ˜¯å¦æ¸…æ™°ï¼ˆRAGã€Agentã€Tool-useã€Memoryã€Fine-tuningï¼‰
- è¯„ä¼°ä½“ç³»æ˜¯å¦å®Œæ•´ï¼ˆç¦»çº¿ã€åœ¨çº¿ã€äººå·¥ã€è‡ªåŠ¨åŒ–ã€å¯¹æŠ—æµ‹è¯•ï¼‰
- å®‰å…¨ä¸åˆè§„ï¼ˆéšç§ã€ç‰ˆæƒã€æç¤ºæ³¨å…¥ã€æ•°æ®å¤–æ³„ï¼‰

è¾“å‡ºæ ¼å¼åŒæ™®é€šå®¡æ ¸ï¼Œä½† P0 å¿…é¡» >= 7 æ¡ï¼Œä¸”æ¯æ¡ç»™å‡ºâ€œå»ºè®®æ”¹æ³•â€ã€‚
"""

SENIOR_POLISH_PROMPT = """
ä½ æ˜¯â€œé«˜çº§æŠ€æœ¯å†™ä½œæ€»ç¼–â€ã€‚è¯·å¯¹ç»ˆç¨¿è¿›è¡Œæœ€åæŠŠå…³ï¼š
- è®©æ–‡ç« è¯»èµ·æ¥æ›´åƒâ€œå·¥ç¨‹å›¢é˜Ÿå†…éƒ¨æŠ€æœ¯ç™½çš®ä¹¦ + å¯¹å¤–ç§‘æ™®â€èåˆä½“
- è¿›ä¸€æ­¥å‹ç¼©å†—ä½™ï¼Œæå‡ä¿¡æ¯å¯†åº¦
- å¢å¼ºå°æ ‡é¢˜çš„å¯æ‰«ææ€§ï¼ˆscannabilityï¼‰
- è¡¥é½å¿…è¦çš„ caveatsï¼ˆé™å®šæ¡ä»¶ï¼‰

åªè¾“å‡ºç»ˆç¨¿æ­£æ–‡ï¼ˆMarkdownï¼‰ã€‚
"""

PROMPTS: Dict[str, str] = {
    "research": RESEARCH_PROMPT,
    "write": WRITING_PROMPT,
    "review": REVIEW_PROMPT,
    "polish": POLISHING_PROMPT,
    "review_senior": SENIOR_REVIEW_PROMPT,
    "polish_senior": SENIOR_POLISH_PROMPT,
}


# -----------------------------
# State definition
# -----------------------------
class AgentState(TypedDict, total=False):
    topic: str
    style: str
    length: int

    research_report: str
    draft: str
    review_suggestions: str
    final_article: str

    # process observability
    log: List[str]                  # human-readable process log
    exception_log: List[str]        # structured exception/retry log

    # retry control
    retry_counts: Dict[str, int]    # per-agent retries (same agent)
    used_fallback: Dict[str, bool]  # whether fallback agent has been used

    # user clarification channel (for L3 retry)
    user_clarifications: Dict[str, str]


# -----------------------------
# Utilities: logging & retry
# -----------------------------
def _now_ts() -> str:
    return _dt.datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def append_log(state: AgentState, header: str, body_md: str) -> None:
    state.setdefault("log", [])
    state["log"].append(f"## {header}\n\n{body_md}\n")


def append_exception(state: AgentState, agent: str, level: str, msg: str, detail: Optional[str] = None) -> None:
    state.setdefault("exception_log", [])
    payload = {
        "time": _now_ts(),
        "agent": agent,
        "retry_level": level,   # L1 / L2 / L3
        "message": msg,
    }
    if detail:
        payload["detail"] = detail
    state["exception_log"].append(json.dumps(payload, ensure_ascii=False))


def should_retry_same_agent(state: AgentState, agent: str, max_times: int = 2) -> bool:
    state.setdefault("retry_counts", {})
    cnt = state["retry_counts"].get(agent, 0)
    return cnt < max_times


def mark_retry_same_agent(state: AgentState, agent: str) -> None:
    state.setdefault("retry_counts", {})
    state["retry_counts"][agent] = state["retry_counts"].get(agent, 0) + 1


def can_use_fallback(state: AgentState, agent: str) -> bool:
    state.setdefault("used_fallback", {})
    return not state["used_fallback"].get(agent, False)


def mark_used_fallback(state: AgentState, agent: str) -> None:
    state.setdefault("used_fallback", {})
    state["used_fallback"][agent] = True


def require_user_clarification(state: AgentState, agent: str, question: str) -> str:
    """
    L3ï¼šå‘ç”¨æˆ·è¯·æ±‚è¡¥å……ä¿¡æ¯ã€‚
    - ä¸ºäº†ä½œä¸šâ€œå¯è‡ªåŠ¨è·‘é€šâ€ï¼Œè¿™é‡Œæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
      1) äº¤äº’å¼ï¼šstdin input
      2) éäº¤äº’ï¼šä½¿ç”¨é»˜è®¤å›ç­”ï¼ˆå¹¶è®°å½•ï¼‰
    """
    state.setdefault("user_clarifications", {})
    if sys.stdin is None or not sys.stdin.isatty():
        # non-interactive fallback
        answer = "é»˜è®¤ï¼šæ— éœ€è¡¥å……ï¼›æŒ‰å¸¸è§„å‡è®¾æ‰§è¡Œï¼ˆé¢å‘å·¥ç¨‹è¯»è€…ï¼Œå¼ºè°ƒè¯„ä¼°ä¸å®‰å…¨ï¼Œå¼•ç”¨å°½é‡ç»™å‡ºé“¾æ¥ï¼‰ã€‚"
        state["user_clarifications"][agent] = answer
        append_exception(state, agent, "L3", "Non-interactive mode: use default clarification", answer)
        return answer

    print("\n" + "=" * 70)
    print(f"âš ï¸ éœ€è¦ç”¨æˆ·è¡¥å……ä¿¡æ¯ï¼ˆä»£ç†ï¼š{agent}ï¼‰")
    print(question)
    print("=" * 70)
    answer = input("ä½ çš„è¡¥å……ä¿¡æ¯ï¼ˆå¯ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤ï¼‰ï¼š ").strip()
    if not answer:
        answer = "é»˜è®¤ï¼šæ— éœ€è¡¥å……ï¼›æŒ‰å¸¸è§„å‡è®¾æ‰§è¡Œï¼ˆé¢å‘å·¥ç¨‹è¯»è€…ï¼Œå¼ºè°ƒè¯„ä¼°ä¸å®‰å…¨ï¼Œå¼•ç”¨å°½é‡ç»™å‡ºé“¾æ¥ï¼‰ã€‚"
    state["user_clarifications"][agent] = answer
    append_exception(state, agent, "L3", "User clarification captured", answer)
    return answer


# -----------------------------
# LLM abstraction
# -----------------------------
class BaseLLM:
    async def ainvoke(self, system_prompt: str, user_content: str) -> str:
        raise NotImplementedError
    
class MockLLM(BaseLLM):
    pass


class TongyiLLM(BaseLLM):
    def __init__(self, model: str = "qwen-plus"):
        self.model = model
        self._llm = ChatTongyi(model=model)

    async def ainvoke(self, system_prompt: str, user_content: str) -> str:
        messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_content)]
        resp = await self._llm.ainvoke(messages)
        return getattr(resp, "content", str(resp))


def build_llm() -> BaseLLM:
    # dotenv load
    if load_dotenv is not None:
        load_dotenv()

    # è‹¥å¯ç”¨ Tongyi ä¸”æä¾› keyï¼Œåˆ™ä½¿ç”¨ï¼›å¦åˆ™ Mock
    key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("DASH_SCOPE_API_KEY")
    if _TONGYI_OK and key:
        return TongyiLLM(model=os.getenv("TONGYI_MODEL", "qwen-plus"))
    return MockLLM()


# -----------------------------
# MCP server (tools)
# -----------------------------
def create_mcp_server() -> "FastMCP":
    if not _FASTMCP_OK:
        raise RuntimeError("fastmcp not installed. Please pip install fastmcp")

    mcp = FastMCP("MCP Writer Tools (Single File)")

    @mcp.tool
    def get_prompt(agent_name: str) -> str:
        """æ ¹æ®ä»£ç†åç§°è·å–å¯¹åº”ç³»ç»Ÿæç¤ºè¯ã€‚"""
        print(f"MCP Server: ğŸ“„ get_prompt('{agent_name}')")
        return PROMPTS.get(agent_name, "Error: Prompt not found.")

    @mcp.tool
    def search(topic: str, max_results: int = 6) -> str:
        """DuckDuckGo æœç´¢å¹¶è¿”å› JSON æ–‡æœ¬ï¼ˆæ¯é¡¹é€šå¸¸åŒ…å« title/href/bodyï¼‰ã€‚"""
        print(f"MCP Server: ğŸ” search('{topic}', max_results={max_results})")
        if not _DDGS_OK:
            return json.dumps({"error": "duckduckgo-search not installed"}, ensure_ascii=False)

        try:
            with DDGS() as ddgs:
                results = list(ddgs.text(topic, max_results=max_results))
            return json.dumps(results, ensure_ascii=False)
        except Exception as e:
            return json.dumps({"error": str(e)}, ensure_ascii=False)

    return mcp


def run_server(host: str, port: int) -> None:
    mcp = create_mcp_server()
    print(f"ğŸš€ MCP Server is running at http://{host}:{port}/mcp")
    # streamable-http æ›´è´´è¿‘â€œå¾®æœåŠ¡å·¥å…·æœåŠ¡å™¨â€
    mcp.run(transport="streamable-http", host=host, port=port)


# -----------------------------
# Agent nodes (LangGraph)
# -----------------------------
@dataclass
class AgentNodes:
    mcp_tools: Dict[str, Any]
    llm: BaseLLM

    async def _call_tool(self, name: str, **kwargs) -> str:
        if name not in self.mcp_tools:
            raise ValueError(f"Tool '{name}' not found on MCP server.")
        tool = self.mcp_tools[name]
        out = await tool.ainvoke(kwargs)
        # MCP adapter å¯èƒ½è¿”å› dict / strï¼Œè¿™é‡Œç»Ÿä¸€æˆ str
        if isinstance(out, (dict, list)):
            return json.dumps(out, ensure_ascii=False)
        return str(out)

    async def research_node(self, state: AgentState) -> AgentState:
        agent = "researcher"
        print("--- èŠ‚ç‚¹: ç ”ç©¶ä»£ç† (Research Agent) ---")

        prompt = await self._call_tool("get_prompt", agent_name="research")
        # æœç´¢ï¼šå¯¹ topic åšä¸€æ¬¡â€œå­¦æœ¯+å·¥ç¨‹â€æ‰©å±•
        topic = state.get("topic", "")
        search_query = f"{topic} RAG retrieval augmented generation evaluation reranking prompt injection arxiv"
        raw_search = await self._call_tool("search", topic=search_query, max_results=8)

        user_content = f"ä¸»é¢˜ï¼š{topic}\n\næœç´¢ç»“æœ(JSON)ï¼š\n{raw_search}\n"
        report = await self.llm.ainvoke(prompt, user_content)

        state["research_report"] = report
        append_log(state, "ç ”ç©¶ä»£ç†è¾“å‡ºï¼ˆResearch Reportï¼‰", report)
        print("âœ… ç ”ç©¶èµ„æ–™ç”Ÿæˆå®Œæ¯•ã€‚")
        return state

    async def writing_node(self, state: AgentState) -> AgentState:
        agent = "writer"
        print("--- èŠ‚ç‚¹: æ’°å†™ä»£ç† (Writing Agent) ---")

        prompt_tpl = await self._call_tool("get_prompt", agent_name="write")
        prompt = prompt_tpl.format(style=state.get("style", "é€šä¿—ä½†ä¸“ä¸š"), length=state.get("length", 1200))

        clar = state.get("user_clarifications", {}).get(agent)
        extra = f"\n\nç”¨æˆ·è¡¥å……ä¿¡æ¯ï¼š{clar}\n" if clar else ""
        user_content = f"{state.get('research_report','')}\n{extra}"

        draft = await self.llm.ainvoke(prompt, user_content)

        state["draft"] = draft
        append_log(state, "æ’°å†™ä»£ç†è¾“å‡ºï¼ˆDraftï¼‰", draft)
        print("âœ… åˆç¨¿å®Œæˆã€‚")
        return state

    async def review_node(self, state: AgentState) -> AgentState:
        agent = "reviewer"
        print("--- èŠ‚ç‚¹: å®¡æ ¸ä»£ç† (Review Agent) ---")

        # æ™®é€šå®¡æ ¸ prompt
        prompt = await self._call_tool("get_prompt", agent_name="review")

        clar = state.get("user_clarifications", {}).get(agent)
        extra = f"\n\nç”¨æˆ·è¡¥å……ä¿¡æ¯ï¼š{clar}\n" if clar else ""
        user_content = f"{state.get('draft','')}\n{extra}"

        suggestions = await self.llm.ainvoke(prompt, user_content)

        state["review_suggestions"] = suggestions
        append_log(state, "å®¡æ ¸ä»£ç†è¾“å‡ºï¼ˆReview Suggestionsï¼‰", suggestions)
        print("âœ… å®¡æ ¸å®Œæˆã€‚")
        return state

    async def polishing_node(self, state: AgentState) -> AgentState:
        agent = "polisher"
        print("--- èŠ‚ç‚¹: æ¶¦è‰²ä»£ç† (Polishing Agent) ---")

        prompt = await self._call_tool("get_prompt", agent_name="polish")

        clar = state.get("user_clarifications", {}).get(agent)
        extra = f"\n\nç”¨æˆ·è¡¥å……ä¿¡æ¯ï¼š{clar}\n" if clar else ""
        user_content = (
            f"æ–‡ç« åˆç¨¿ï¼š\n\n{state.get('draft','')}\n\n"
            f"å®¡æ ¸å»ºè®®ï¼š\n\n{state.get('review_suggestions','')}\n"
            f"{extra}"
        )

        final_article = await self.llm.ainvoke(prompt, user_content)

        state["final_article"] = final_article
        append_log(state, "æ¶¦è‰²ä»£ç†è¾“å‡ºï¼ˆFinal Articleï¼‰", final_article)
        print("âœ… ç»ˆç¨¿ç”Ÿæˆå®Œæˆã€‚")
        return state


# -----------------------------
# Retry wrapper for nodes
# -----------------------------
async def run_with_retry(
    state: AgentState,
    agent_name: str,
    primary_fn,
    fallback_fn=None,
    clarification_question: Optional[str] = None,
) -> AgentState:
    """
    ä¸‰çº§é‡è¯•ç­–ç•¥ï¼ˆæ‰©å±•é¡¹ï¼‰ï¼š
      L1ï¼šåŒä¸€ä»£ç†é‡è¯•ï¼ˆæœ€å¤š 2 æ¬¡ï¼‰
      L2ï¼šåˆ‡æ¢å¤‡ç”¨ä»£ç†ï¼ˆä¸€æ¬¡ï¼‰
      L3ï¼šå‘ç”¨æˆ·è¯·æ±‚è¡¥å……ä¿¡æ¯ï¼ˆä¸€æ¬¡ï¼‰ -> å†æ‰§è¡Œä¸»ä»£ç†ï¼ˆä¸€æ¬¡ï¼‰
    """
    # L1
    while True:
        try:
            return await primary_fn(state)
        except Exception as e:
            detail = repr(e)
            if should_retry_same_agent(state, agent_name, max_times=2):
                mark_retry_same_agent(state, agent_name)
                append_exception(state, agent_name, "L1", "Retry same agent", detail)
                print(f"âš ï¸ {agent_name} å¤±è´¥ï¼ŒL1 é‡è¯•ä¸­... ({state['retry_counts'][agent_name]}/2)")
                continue
            break

    # L2
    if fallback_fn is not None and can_use_fallback(state, agent_name):
        try:
            mark_used_fallback(state, agent_name)
            append_exception(state, agent_name, "L2", "Switch to fallback agent", "fallback invoked")
            print(f"âš ï¸ {agent_name} å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å¤‡ç”¨ä»£ç†ï¼ˆL2ï¼‰...")
            return await fallback_fn(state)
        except Exception as e:
            append_exception(state, agent_name, "L2", "Fallback failed", repr(e))

    # L3
    if clarification_question:
        _ = require_user_clarification(state, agent_name, clarification_question)
        try:
            append_exception(state, agent_name, "L3", "Re-run after clarification", "re-run primary")
            print(f"âš ï¸ {agent_name} è¿›å…¥ L3ï¼šå·²è·å–è¡¥å……ä¿¡æ¯ï¼Œé‡æ–°æ‰§è¡Œä¸»ä»£ç†...")
            return await primary_fn(state)
        except Exception as e:
            append_exception(state, agent_name, "L3", "Failed after clarification", repr(e))

    # æ— æ³•æ¢å¤ï¼šä¿ç•™çŠ¶æ€å¹¶æŠ›å‡º
    raise RuntimeError(f"Agent '{agent_name}' failed after retry strategy. See exception_log.")


# -----------------------------
# Graph construction
# -----------------------------
async def create_graph(mcp_session) -> Any:
    if not (_LANGGRAPH_OK and _MCP_ADAPTER_OK):
        raise RuntimeError("Missing langgraph or langchain-mcp-adapters dependencies.")

    mcp_tools_list = await load_mcp_tools(mcp_session)
    mcp_tools = {t.name: t for t in mcp_tools_list}

    llm = build_llm()
    nodes = AgentNodes(mcp_tools=mcp_tools, llm=llm)

    # fallback agents: use senior prompts by calling get_prompt with review_senior / polish_senior
    async def review_fallback(state: AgentState) -> AgentState:
        agent = "reviewer"
        print("--- èŠ‚ç‚¹: å¤‡ç”¨å®¡æ ¸ä»£ç† (Senior Review) ---")
        prompt = await nodes._call_tool("get_prompt", agent_name="review_senior")
        user_content = state.get("draft", "")
        suggestions = await llm.ainvoke(prompt, user_content)
        state["review_suggestions"] = suggestions
        append_log(state, "å¤‡ç”¨å®¡æ ¸ä»£ç†è¾“å‡ºï¼ˆSenior Review Suggestionsï¼‰", suggestions)
        return state

    async def polish_fallback(state: AgentState) -> AgentState:
        agent = "polisher"
        print("--- èŠ‚ç‚¹: å¤‡ç”¨æ¶¦è‰²ä»£ç† (Senior Polish) ---")
        prompt = await nodes._call_tool("get_prompt", agent_name="polish_senior")
        user_content = (
            f"æ–‡ç« åˆç¨¿ï¼š\n\n{state.get('draft','')}\n\n"
            f"å®¡æ ¸å»ºè®®ï¼š\n\n{state.get('review_suggestions','')}\n"
        )
        final_article = await llm.ainvoke(prompt, user_content)
        state["final_article"] = final_article
        append_log(state, "å¤‡ç”¨æ¶¦è‰²ä»£ç†è¾“å‡ºï¼ˆSenior Final Articleï¼‰", final_article)
        return state

    workflow = StateGraph(AgentState)

    workflow.add_node(
        "researcher",
        lambda s: run_with_retry(
            s,
            "researcher",
            nodes.research_node,
            fallback_fn=None,
            clarification_question="è¯·è¡¥å……ï¼šæ–‡ç« è¯»è€…æ˜¯è°ï¼ˆå·¥ç¨‹/ç§‘ç ”/äº§å“ï¼‰ï¼Ÿæ˜¯å¦éœ€è¦èšç„¦æŸä¸ªå­æ–¹å‘ï¼ˆè¯„ä¼°/å®‰å…¨/ç³»ç»Ÿæ¶æ„ï¼‰ï¼Ÿ",
        ),
    )
    workflow.add_node(
        "writer",
        lambda s: run_with_retry(
            s,
            "writer",
            nodes.writing_node,
            fallback_fn=None,
            clarification_question="è¯·è¡¥å……ï¼šæ–‡ç« é£æ ¼ä¸é‡ç‚¹ï¼ˆæ›´å­¦æœ¯/æ›´å·¥ç¨‹/æ›´é¢å‘ä¸šåŠ¡ï¼‰ï¼Ÿæ˜¯å¦éœ€è¦æ¡ˆä¾‹ï¼ˆåŒ»ç–—/é‡‘è/å®¢æœ/ä»£ç æ£€ç´¢ï¼‰ï¼Ÿ",
        ),
    )
    workflow.add_node(
        "reviewer",
        lambda s: run_with_retry(
            s,
            "reviewer",
            nodes.review_node,
            fallback_fn=review_fallback,
            clarification_question="è¯·è¡¥å……ï¼šä½ æ›´åœ¨æ„å“ªç±»é—®é¢˜ï¼ˆäº‹å®æ­£ç¡®æ€§/å·¥ç¨‹è½åœ°/å†™ä½œè¡¨è¾¾/å¼•ç”¨å®Œæ•´æ€§ï¼‰ï¼Ÿ",
        ),
    )
    workflow.add_node(
        "polisher",
        lambda s: run_with_retry(
            s,
            "polisher",
            nodes.polishing_node,
            fallback_fn=polish_fallback,
            clarification_question="è¯·è¡¥å……ï¼šæ˜¯å¦éœ€è¦æ›´çŸ­/æ›´é•¿ï¼Ÿæ˜¯å¦éœ€è¦åŠ å…¥å°ç»“ã€è¦ç‚¹åˆ—è¡¨æˆ–æ›´å¼ºçš„ç»“è¯­å»ºè®®ï¼Ÿ",
        ),
    )

    workflow.set_entry_point("researcher")
    workflow.add_edge("researcher", "writer")
    workflow.add_edge("writer", "reviewer")
    workflow.add_edge("reviewer", "polisher")
    workflow.add_edge("polisher", END)

    return workflow.compile()


# -----------------------------
# Client runner
# -----------------------------
def build_initial_state(topic: str, style: str, length: int) -> AgentState:
    return AgentState(
        topic=topic,
        style=style,
        length=length,
        log=[f"# å¤šä»£ç†åä½œå†™ä½œæµç¨‹è®°å½•\n\n**ä»»åŠ¡ä¸»é¢˜ï¼š** {topic}\n\n**é£æ ¼ï¼š** {style}\n\n**ç›®æ ‡é•¿åº¦ï¼š** {length}\n"],
        exception_log=[],
        retry_counts={},
        used_fallback={},
        user_clarifications={},
    )


def render_output_markdown(final_state: AgentState) -> str:
    topic = final_state.get("topic", "æœªå‘½åä¸»é¢˜")
    final_article = final_state.get("final_article", "æœªèƒ½ç”Ÿæˆæœ€ç»ˆæ–‡ç« ã€‚")
    process_log = "\n".join(final_state.get("log", []))

    # å¼‚å¸¸å¤„ç†æ—¥å¿—ï¼ˆæ‰©å±•é¡¹ï¼‰
    ex_lines: List[str] = []
    for line in final_state.get("exception_log", []):
        try:
            obj = json.loads(line)
            ex_lines.append(
                f"- {obj.get('time')} | agent={obj.get('agent')} | level={obj.get('retry_level')} | {obj.get('message')}"
                + (f" | detail={obj.get('detail')}" if obj.get("detail") else "")
            )
        except Exception:
            ex_lines.append(f"- {line}")

    exception_md = "æ— ã€‚\n" if not ex_lines else "\n".join(ex_lines) + "\n"

    return (
        f"# æœ€ç»ˆæ–‡ç« ï¼š{topic}\n\n"
        f"{final_article}\n\n"
        f"---\n\n"
        f"# æ‰§è¡Œè¿‡ç¨‹è®°å½•\n\n"
        f"{process_log}\n\n"
        f"---\n\n"
        f"# å¼‚å¸¸å¤„ç†æ—¥å¿—\n\n"
        f"{exception_md}"
    )


async def run_client(
    server_url: str,
    topic: str,
    style: str,
    length: int,
) -> str:
    if not _MCP_ADAPTER_OK:
        raise RuntimeError("langchain-mcp-adapters not installed.")
    if not _LANGGRAPH_OK:
        raise RuntimeError("langgraph not installed.")

    client = MultiServerMCPClient(
        {
            "tools_server": {
                "url": server_url,
                "transport": "streamable_http",
            }
        }
    )

    async with client.session("tools_server") as mcp_session:
        print("âœ… MCP å®¢æˆ·ç«¯å·²è¿æ¥åˆ°å·¥å…·æœåŠ¡å™¨ã€‚")
        app = await create_graph(mcp_session)

        print("\n" + "=" * 70)
        print("ğŸš€ LangGraph å¤šä»£ç†å·¥ä½œæµå¯åŠ¨")
        print("=" * 70 + "\n")

        state = build_initial_state(topic=topic, style=style, length=length)
        final_state = await app.ainvoke(state)

        md = render_output_markdown(final_state)
        return md


def write_output_file(md: str) -> str:
    ts = _dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    out = f"article_output_{ts}.md"
    with open(out, "w", encoding="utf-8") as f:
        f.write(md)
    return out


# -----------------------------
# CLI
# -----------------------------
def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(prog="multi-agent-mcp", add_help=True)

    sub = p.add_subparsers(dest="cmd", required=True)

    sp = sub.add_parser("server", help="Run MCP tool server")
    sp.add_argument("--host", default="127.0.0.1")
    sp.add_argument("--port", type=int, default=8000)

    cp = sub.add_parser("client", help="Run LangGraph multi-agent client")
    cp.add_argument("--server-url", default="http://127.0.0.1:8000/mcp")
    cp.add_argument("--topic", default="å†™ä¸€ç¯‡ä»‹ç»RAGçš„ç†è®ºä¸ç ”ç©¶å‰æ²¿çš„æ–‡ç« ")
    cp.add_argument("--style", default="é€šä¿—ä½†ä¸“ä¸š")
    cp.add_argument("--length", type=int, default=1400)

    return p.parse_args()


def main() -> None:
    args = parse_args()

    if args.cmd == "server":
        if not _FASTMCP_OK:
            print("ERROR: fastmcp not installed. pip install fastmcp")
            sys.exit(2)
        run_server(args.host, args.port)
        return

    if args.cmd == "client":
        try:
            md = asyncio.run(run_client(args.server_url, args.topic, args.style, args.length))
            out = write_output_file(md)
            print("\n" + "=" * 70)
            print("âœ… ä»»åŠ¡å®Œæˆ")
            print(f"ğŸ‰ è¾“å‡ºæ–‡ä»¶ï¼š{out}")
            print("=" * 70 + "\n")
        except KeyboardInterrupt:
            print("\nç¨‹åºå·²ç”±ç”¨æˆ·ä¸­æ–­ã€‚")
        except Exception as e:
            print("\nå‘ç”Ÿé”™è¯¯ï¼š", repr(e))
            print("\næ’æŸ¥å»ºè®®ï¼š")
            print("1) ç¡®ä¿å·²å¯åŠ¨ MCP Serverï¼špython main.py server")
            print("2) ç¡®ä¿ä¾èµ–å·²å®‰è£…ï¼šfastmcp duckduckgo-search langgraph langchain langchain-mcp-adapters")
            print("3) è‹¥éœ€çœŸå® LLMï¼šè®¾ç½® DASHSCOPE_API_KEYï¼›å¦åˆ™ä¼šä½¿ç”¨ MockLLMï¼ˆä»å¯è¿è¡Œï¼‰")
            sys.exit(1)
        return


if __name__ == "__main__":
    main()
