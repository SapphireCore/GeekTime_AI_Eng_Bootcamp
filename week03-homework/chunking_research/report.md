# 作业一实验报告：句子切片在 LlamaIndex RAG 系统中的效果分析

## 1. 项目背景与目标

在基于检索增强生成（RAG）的系统中，文本切片（Chunking）策略直接决定了“能否检索到正确知识”以及“生成回答是否连贯准确”。本实验基于 LlamaIndex 框架，系统性比较不同切片策略在真实长文本场景下的表现，重点分析**句子切片与句子窗口切片**在精确性与上下文完整性之间的权衡。

实验文本采用 **Markdown 格式的长文档（>1000 字）**，主题为“剧本杀新手知识普及”，内容包含复杂句式与多段落结构，具有良好的代表性。

---

## 2. 系统架构设计

整体流程如下：

Markdown 文档 ->
NodeParser（不同切片策略）->
Embedding（DashScope Text Embedding）->
VectorStoreIndex ->
Query Engine（Top-K 检索）-> 
上下文拼接 -> 
LLM（Qwen-plus）生成回答 ->
自动 + 人工评估


系统以**单一 Python 文件**实现，避免工程复杂度，便于课程作业提交与复现。

---

## 3. 切片策略说明

### 3.1 SentenceSplitter（句子切片）
- 以句子为基本单位，结合 `chunk_size` 与 `chunk_overlap`
- 优点：语义完整性好，适合自然语言文档
- 风险：上下文可能不足

### 3.2 TokenTextSplitter（Token 切片）
- 按 Token 数进行硬切
- 优点：实现简单、控制精确
- 缺点：容易破坏句子结构，影响语义理解

### 3.3 SentenceWindowNodeParser（句子窗口）
- 索引阶段：按句子切分
- 检索后：自动拼接前后窗口句子
- 优点：兼顾精确检索与上下文完整性
- 缺点：实现复杂度略高

### 3.4 MarkdownNodeParser
- 利用 Markdown 结构（标题、段落）
- 特别适合结构化说明文档

---

## 4. 评估方法

### 4.1 自动评估指标
1. **上下文是否包含答案关键信息**
2. **LLM-as-Judge 判断回答准确性**

### 4.2 人工评估指标
- **上下文冗余度（1–5 分）**
  - 1：几乎无冗余
  - 5：大量无关信息

---

## 5. 实验结果与分析

### 5.1 关键参数影响

- **chunk_size** 是影响最大的参数  
  - 过小：检索精准但信息不完整  
  - 过大：上下文充足但噪声增加  

- **chunk_overlap**
  - 太小：易割裂语义
  - 太大：显著增加冗余与成本

### 5.2 不同策略对比总结

| 策略 | 检索精度 | 上下文完整性 | 冗余度 | 综合评价 |
|----|----|----|----|----|
| TokenTextSplitter | 中 | 低 | 低 | 不推荐 |
| SentenceSplitter | 高 | 中 | 中 | 推荐 |
| SentenceWindow | 高 | 高 | 中 | **最佳** |
| MarkdownParser | 中-高 | 高 | 中 | 文档型最佳 |

---

## 6. 权衡与设计经验

在“精确检索”与“上下文丰富性”之间，单纯调整 `chunk_size` 和 `overlap` 往往不足。**SentenceWindowNodeParser** 通过“索引精细、生成扩展”的方式，实现了工程上更优雅的折中方案，是当前 RAG 场景下的推荐实践。

---

## 7. 已知限制与扩展方向

### 限制
- 冗余度评分依赖人工输入
- 样本问题数量有限

### 可扩展方向
- 引入多问题自动评估
- 结合 rerank 模型
- 加入两阶段检索（Parent-Child Chunking）

---

## 8. 结论

本实验验证了：  
**切片策略本身就是 RAG 系统中最重要的“模型参数之一”。**  
在长文本、说明性文档场景下，句子窗口切片在效果与稳定性上表现最优，具备明确的工程实践价值。



